# learning_curve
The existence of large volumes of data has considerably alleviated concerns regarding the availability of sufficient data instances for machine learning experiments. Nevertheless, in certain contexts, addressing limited data availability may demand distinct strategies and efforts. The data modeling process used for epidemiologic analysis to predict the COVID-19 pandemic evolution at its beginning, emerged a question: how much data is needed to make reliable predictions? When does the volume of data provide a better understanding of the disease's evolution and, in turn, offer reliable forecasts? The asymptotic exponential curve fitting enabled the evaluation of the errors in different points, reflecting the increased available data over time. For a comprehensive understanding of the results at distinct stages of the time evolution, the average derivative of the curves and the equilibrium points were calculated, aimed to identify the convergence of the ARIMA models to a stable pattern.
